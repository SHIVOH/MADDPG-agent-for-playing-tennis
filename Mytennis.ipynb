{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, a solution is provided to the third project in Udacity's Deep Reinforcement Learning Nanodegree.\n",
    "\n",
    "The solution uses a single actor-critic style DDPG agent as the \"brain\" for both of the players in the game because in this game the observations for the two players are symetrical, and the players should react to the same state inputs with the same actions.\n",
    "\n",
    "Both player's experiences are stored in a single replay buffer for the DDPG agent to learn. As shown below, the agent is able to solve the environment in 1500 episodes (100_episode_average_score=0.5), and further improves the score to 1.4+ at 1812 episode.\n",
    "\n",
    "Here are the recorded actions of the agent before and after the training. It seems the agent learned to play the game pretty well.\n",
    "\n",
    "### Before Training\n",
    "![title](before_training.gif)\n",
    "\n",
    "### After Training\n",
    "![title](after_training.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Start the environment and agent\n",
    "\n",
    "We begin by importing the necessary packages, and initiate the enviroment as well as the DDPG agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "from ddpg_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# instantiate the environment and agent\n",
    "env = UnityEnvironment(file_name=\"/home/labassistant/deep-reinforcement-learning/p3_collab-compet/Tennis_Linux/Tennis.x86_64\")\n",
    "agent = Agent(state_size=24, action_size=2, random_seed=2)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# get the number of agents in the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "num_agents = len(env_info.agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Show the network archetecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Actor Network:\n",
      " Actor(\n",
      "  (fc1): Linear(in_features=24, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc3): Linear(in_features=4, out_features=2, bias=True)\n",
      ") \n",
      "\n",
      "Target Actor Network:\n",
      " Actor(\n",
      "  (fc1): Linear(in_features=24, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc3): Linear(in_features=4, out_features=2, bias=True)\n",
      ") \n",
      "\n",
      "Local Critic Network:\n",
      " Critic(\n",
      "  (fc1): Linear(in_features=24, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=34, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc4): Linear(in_features=8, out_features=1, bias=True)\n",
      ") \n",
      "\n",
      "Target Critic Network:\n",
      " Critic(\n",
      "  (fc1): Linear(in_features=24, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=34, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc4): Linear(in_features=8, out_features=1, bias=True)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Local Actor Network:\\n', agent.actor_local, '\\n')\n",
    "print('Target Actor Network:\\n', agent.actor_target, '\\n')\n",
    "print('Local Critic Network:\\n', agent.critic_local, '\\n')\n",
    "print('Target Critic Network:\\n', agent.critic_target, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define training process details\n",
    "\n",
    "#### Hyper Parameters\n",
    "- BUFFER_SIZE = 100000 (replay buffer size)\n",
    "- BATCH_SIZE = 300 (minibatch size)\n",
    "- GAMMA = 0.99 (discount factor)\n",
    "- TAU = 1e-3 (for soft update of target parameters)\n",
    "- LR_ACTOR = 1e-4 (learning rate of the actor)\n",
    "- LR_CRITIC = 1e-3 (learning rate of the critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=2000, print_every=400):\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    environment_solved = False\n",
    "    environment_solved_episode = 0\n",
    "    best_performance_episode = 0\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        while True:\n",
    "            if i_episode > 1000:\n",
    "                actions = agent.act(states, noise_level=0)\n",
    "            else:\n",
    "                actions = agent.act(states, noise_level=1)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            agent.memorize(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            score += rewards\n",
    "            agent.learn()\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        episode_score = np.max(score)\n",
    "        scores_deque.append(episode_score)\n",
    "        scores.append(episode_score)\n",
    "        \n",
    "        if (not environment_solved) and np.mean(scores_deque)>0.5 :\n",
    "            environment_solved_episode = i_episode\n",
    "            environment_solved = True\n",
    "        \n",
    "        if np.mean(scores_deque) > best_score:\n",
    "            torch.save(agent.actor_local.state_dict(), 'best_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'best_critic.pth')\n",
    "            best_score = np.mean(scores_deque)\n",
    "            best_performance_episode = i_episode\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "    \n",
    "    print(\n",
    "        'Environment solved in {} episodes. Best average score of {} reached at {} episodes.'.format(\n",
    "            environment_solved_episode, best_score, best_performance_episode))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start the training and plot the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400\tAverage Score: 0.07\n",
      "Episode 800\tAverage Score: 0.09\n",
      "Episode 1200\tAverage Score: 1.23\n",
      "Episode 1600\tAverage Score: 0.13\n",
      "Episode 2000\tAverage Score: 1.50\n",
      "Environment solved in 1134 episodes. Best average score of 1.633600024357438 reached at 1394 episodes.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0P0lEQVR4nO2deZgcVfX3v2eW7BtJJhCyTVYhQoAkEKIEkSBbUBRQVkHUFxGQRX01En6A/ngRUdmRRUQWEaKs0SQsSVjCkmUC2dfJvs1kkklmMnv3zHn/6Oqe6pqq6uruurV0n8/zzDNVt27XPXW765y7nHsuMTMEQRCE/KXAbwEEQRAEfxFDIAiCkOeIIRAEQchzxBAIgiDkOWIIBEEQ8pwivwVIl/79+3NpaanfYgiCIISKZcuW7WfmErNroTMEpaWlKCsr81sMQRCEUEFE262uydCQIAhCniOGQBAEIc8RQyAIgpDniCEQBEHIc8QQCIIg5DliCARBEPIcMQSCIAh5TujWEQhCPlJR04SfvFiGX597DP6zci8+2liFpkgr/vjdcTjUEEF1fQt+PGUEVu+uQbSNceKQPh3u8Un5fnywYR9mTBubSHtt2S48NH8jdlY34qxjj8S8dZUAgK7FhRjStyueu/YUHN2na9J9ZryxCi8t3oFLJgzGPd8+Dl2KC5U+e7q8umwXHnxvI3YfagQAzL1lCo4d2Ms0LzNjxpursWZ3DQ41RvDU9ydgVEkPvP7FblwyfjAKCshV2SKtbTj3oY+wuaoeAHD7+cfgutNHJq4vWF+JY47qhaP7dMXbqyvwxhe7sP1AA9ZXHMY/fjQJp43u76o8cShs+xFMnDiRZUGZkG9c/+IyvL2mwjbP2t+dg7F3vgMA2HbftA7XS6fPBgB8Mv1MDOrTFa1tjJG3z7G955TR/fHijyYlzitrmzDp3vmJ8yevGo9zjxvo+Dm8IP6ceszqAwC27q/H1//0QeK8f49O+OFpw3H/2xtw/yXj8L2JQ1yV7bEFm/CndzdaylY6fTYG9OyMJTPOSus5nEBEy5h5otk1GRoShBCwcd/hlHkIzlqvbW2xxl+ktS1l3k2VdUnnzZHkzzRHU98jyDRHW5PO99e1YF9tMwCgvjnqenn7DjdbXos3yu3yqEIMgSCEgGhr6p47ORzFKCqMZXRiCIz3NJ4XF4ZbhZjVa7QtVi9FCp4t2mb9PUYcfMeqCPe3KAh5ghOl7ZSigthr78S4GEeO2wwJBU6tT0Axq9d4vRS5PD8AABGbHlTcACkoNiViCAQhBLjZWiwscN4jYCSXa5RDhbL0ErN6jSg0BLY9gqhWrg+9LDEEghAC4q1FO5z6fcTHoiM2SimOcd7BKEdhYbgNQdSsR5AYGlLQI7AxvhGt3GIfjKu4jwqCTxyoa0ZxUQEKiNCpsACdipLbZXsONaKhpRWR1jYcaoi4Xr7dMEUcY4+gw3BSwJwOG1rMJ3ibIq1oY0Z9cyu6dipEj85FONwUQZNhshhof0YV8x81jR2/x7Y2RkEBJcq16/1V1jbhyF5dXJdLDIEg+EB9cxQT7pmXOJ80vC9m/mRy4vzt1RW4/h/L0rqnUWmnYn1Fak+koX27JZ0bW7TplqmauPuskSn3v48qnTfOtvum4fi730WX4o7KPv6MKoaGFm7a3yHtoXkb8fOzv5Qot8Wm1/DQvE34/UXHuy6XDA0Jgg8YXRMXb61OOl+05YByGazmef/PlOG4Y9qxAIDJI/olXYur/fg8Q1iWIVVZuGQ2GdxhkxeeqRui6apbhDd3tf36ED2HGlpUiCOGQBCEZGZMG4sfTxlhaijiiv+2s0YnnecKxUnzAuoe7t6LjkuZp3fX4g5pqupbDIEg5AiOJ4tdKIs0K5FjdgCA8/UYuYQYAkHIU5wYjo5ZYilxZRm2EDWp8OpxzFaBG8s2q1tVRkqZISCiIUT0PhGtJaI1RHSLSZ4ziKiGiJZrf3eqkkcQch23dZiZzonrpoIc7hHkIyq9hqIAfsHMnxNRTwDLiOg9Zl5ryLeQmS9QKIcgCC4TNxI51iFIwrPeQQCGopT1CJh5LzN/rh0fBrAOwCBV5QmCoJ64bmwPLZF7lsBp8D7VeFmznswREFEpgJMALDa5PJmIVhDRXCL6ssXnryOiMiIqq6qqUimqIIQWp+P17dnSjzUUp32OwFGRoSJoayO8QLkhIKIeAF4DcCsz1xoufw5gGDOfAOBRAG+a3YOZn2bmicw8saSkRKm8giDEIJMxi7jiz1WvIa+MgKlrro+1qdQQEFExYkbgJWZ+3XidmWuZuU47ngOgmIjUbMEjCDmOl2okl+cIgjI05CUqvYYIwN8ArGPmByzyHKXlAxGdosmjfkmlIAgZER9+ikdfyOVhFN+fzEMBVHoNfRXA9wGsIqLlWtrtAIYCADM/CeASAD8loiiARgCXca45JgtCQHG2jsA8U0HIQkwI9igzBMz8MVIE62DmxwA8pkoGQcgnnK8sdpbRdB1B/Jo2yG3cqCbs+Pk4fpYtK4sFQXBM+4Iyf+VQidd+/VZzEmZ2IXQriwVBCD+W7qOQoSG3CMI8ixgCQcgV0tQnqbLbuTjmw2RxEJHoo4IgBIZcXVDmx/MkeldO8srQkCAIdjhunWej7IwLynLMEOjx+9m8dKAUQyAIgiVWqih3Iw15M1lstmrbT8QQCEKekqrBaRozX/ufCEPtd7NZcAUxBIKQI3ihkxPuo5rmEDOgjpyLPioIQm6R6C2E1BJY9WQ46djbAHR+9q7EEAhCjuBUjaSjbjpsn2jcqjKslsAGr4POBWF0TQyBIOQpKZW4jT7MZa8hL4xbsKaKxRAIgpAGxhATYbUDQTJgVg5EXsoohkAQAkgm48VejjHnaogJZvZtPwI/q1IMgSAIlhiHSdrdR82v5xJBNHKqjJQYAkEIIJksOHI8WczJ/y1lsLuWCEPtsNCA4bfYAVtPJoZAEATnGHcoC2SzOUcw622p6oGJIRCEABKYFbsd3EdjBC1Egqv49GiyMY0gCFnjtiKx0/VhNwOBMbRpInMEgiC4SkaqMJz6M5SI+6gg5DmZTRY70xxujDNTyNcR+I1fLqpWiCEQhAASlKELoxTGEBNhxUntBuMb8AYxBIIgmGLXag1ai9YtmP2c/5Cgc4IgZEu6exZntHo57Y8IGSJhqAUh10nR7Ay8e2bI9ywOq9yqEEMgCH6QQhFl1Fp3mi+NWxvliJ8G3Ey5gsp5mqDZeTEEgiCYYqascn1BmR+xkyxDfoj7qCAIQSbsZsCJwvfK2AXBpiozBEQ0hIjeJ6K1RLSGiG4xyUNE9AgRlRPRSiIar0oeQch1vNmz2LBDWQ4Ptnv1bGkVo8hoFKm5LQAgCuAXzPw5EfUEsIyI3mPmtbo85wEYrf1NAvCE9l8QhABgpaRy1X0UyN1hLzuU9QiYeS8zf64dHwawDsAgQ7YLAbzAMRYB6ENEA1XJJAi5jPOVxdr/DMJQ50r73+rZvergOKlb0+9TkXyezBEQUSmAkwAsNlwaBGCn7nwXOhoLENF1RFRGRGVVVVXK5BQEwRl52GjOaZQbAiLqAeA1ALcyc20m92Dmp5l5IjNPLCkpcVdAQRAs6dBKNbiP5koPwU/S8lRSZICVGgIiKkbMCLzEzK+bZNkNYIjufLCWJgi5jYIX2v0w1DYDGDncIwjKo+VE9FGK/Yr+BmAdMz9gkW0WgKs176FTAdQw815VMglCYAhAUzobn/lcniwOwFfjOSq9hr4K4PsAVhHRci3tdgBDAYCZnwQwB8D5AMoBNAC4VqE8gpDTOF9ZnLmqy2FvUQDeGQF9ZytuVP2sW2WGgJk/RopeFsd+kTeqkkEQwkpQ9K2l+2gOxxryuq/jx2pmI7KyWBAEU+xcHHN3YKgdr4ycpSurN8UDEEMgCP6QKvpoBrdMd8gnG0WXj4uuVBGEqhRDIAh+4P9oQEaEdSjIiNVwjJ8hM/wcIhJDIAgBJCj61ko55fKexd600NsLCYJxFUMgCDmCU4XiWPGYhqFmq0s5h9+TuF72TsQQCIIfKJgjSJdM9ExiZXE+WIIAoqraxRAIgh+k2qHMGymyINyWwImnjteL5pwYZlW/CzEEgiBYYlRO7TuUxa8H32RlisqhIX2PyqoUcR8VhBCys7oBL3y2zW8xXMOsPfzumgrLa7lCkJ9NlWwqQ0wIQl5x5TOLsaO6AReeOAi9uxZ7Xn66jfNMWpz/XZkbocCC1I8JguGRHoEguMShhpbYQZC0jCJkQZl7BOHnIoZAEFwinRdaxcvv9pi2nbLPWTOgq0K3pz+s5lPi6R3mY3IhDLUgCLlL2DsEdpPcXvR29CUEoXclhkAQXML/1zk9svH4yeX9CFQRZAcrMQSC4BJ+v+euryxGbruHCu2IIRCEHKEp2urq/exGLEK/H4FJGpFaY265XiA+R+CgdFlQJggBJ53BEhUK9KZ/fuH+TfMI4/cXViOXCWIIBMEl/NYb5fvq0spvJu8bN3zF0WcDML8ZOvTDbPoJYpksFgQhUHTtVJh07rdxU4VZa99Lhaw3CmbzMF7PzYghEASX8L9d5wyn6w3sniex4XpYTYVV0DlmZd9jqprycyhKDIEguER6C8pCqkA1AjCa4Tod5ghUlpVpBSoSSgyBIAQQT1qHZsMjDtvDYTcEZoZY9TPpv9NURXndOxBDIAguEXLdaIqVQsqHBWVePWEQ+oZiCATBJdx8oYPQ4raNNRT2dQQWvSF9stuPpu+FmN37uhfKXC7ROWIIBCHPcEN5B8BOZYVpFZDhv8fsqWlKmUfV3JIYAkFwCTcXlHnR0na2kjWkTf6Ak3KOwBMp2hFDIAgukQsqUz8aZOs+GvYugQ8kTRbr6y8APxwxBIIgZEB8HUE4cbJgy7NFXQEwqsoMARE9S0T7iGi1xfUziKiGiJZrf3eqkkUQwkbQW9xBly8VpkHnEGu1e+ERFbRJdpV7Fj8H4DEAL9jkWcjMFyiUQRC8xwU9olJRxG/tpIygKSyVGI2bZ49uUpD1bmZqRFDWI2DmjwBUq7q/IAQWJwrWJC3doHGqsQ1D7Z0YSjBTqM3RNuyobnA9nLdZmUHrUTk2BETUlYi+5HL5k4loBRHNJaIv25R9HRGVEVFZVVWVyyIIQjC48LGP/RbBsYKPrzHIpR5D/Flmr9zrryA+4MgQENE3ASwH8LZ2fiIRzcqy7M8BDGPmEwA8CuBNq4zM/DQzT2TmiSUlJVkWKwiKybC1V9+ipiWqgoA1aNPGkVus25vXp3HDoLqP3g3gFACHAICZlwMYnk3BzFzLzHXa8RwAxUTUP5t7CkIgCEkr2YmYVnmCNrSRNj5/R5n2pPyeI4gwc40hLSuRiOgo0vqXRHSKJsuBbO4pCEJqnLtFhl3bZ4fbi+msqj0I7QanXkNriOgKAIVENBrAzQA+tfsAEb0M4AwA/YloF4C7ABQDADM/CeASAD8loiiARgCXseyULeQJYf+ph34/Ap9xunDPK5wagp8BmAGgGcA/AbwD4B67DzDz5SmuP4aYe6kg5BRhVo5Oh3zCPjTkaFjM9TkC5+letxNSGgIiKgQwm5m/jpgxEARBEc3RVnQuKkydMQuibTEtk8/rCHL1uTIl5RwBM7cCaCOi3h7IIwh5zV1vrVFexn1z1zvKZ7uOIORhqP0m48liRb1Np0NDdQBWEdF7AOoTQjHfrEQqQQgx2bS0v9hxyFVZzFixM/syvNzoXQXOIq+6XGYa2t/r4UWnhuB17U8QBA/wb57B2c694TYD/hM0O+rIEDDz80TUCcAYLWkDM0fUiSUIgmpSGZuA6SpX8WN+xHKyOADja44MARGdAeB5ANsQ+30MIaJrtHhCgiDocOO1DvqewEFr0eYLqmyG06GhPwM4m5k3AAARjQHwMoAJasQSBCHIBN1QpcLZqmp1C8qSA9B1rEuvOwlOVxYXx40AADDzRmiLwwRBcB+VcwTp3NlKIUmPwD1CMzQEoIyIngHwD+38SgBlakQShHAThBfbCWZiJq14NSj7mUt3qBXIQ5ztUOZ2oe2H+ro1K2Z/XbPLhdvj1BD8FMCNiIWWAICFAP6iRCJBEAI59PLogvLEcfs6gnAYPSNBEtvsm16397CnMjg1BEUAHmbmB4DEauPOyqQSBCFwJMfHCZ6hCjpuDPepsl9O5wjmA+iqO+8KYJ774ghC+HHjZQ1KvKIgtZy9RuWjB61enRqCLvG9AwBAO+6mRiRByH38VATx4ZxUIti1+mWyOH2CHIbaqSGoJ6Lx8RMimohY6GhBEHIIO/2uNwzxo6C1bJ3iSG6FD5fKkHo99+J0juBWAP8moj3a+UAAlyqRSBBCTliVYzqEPdZQWPFlhzIiOpmIjmLmpQCOATATQASxvYu3qhFJEISgoJ+ryCXd70vQOav0ADQcUg0NPQWgRTueDOB2AI8DOAjgaYVyCUJOE4jJ4BQayDYMtcuiuE3PzkW484KxfothSSrl7/WvI9XQUCEzV2vHlwJ4mplfA/AaES1XKpkghJRAKHkb7KSzG/KhpHyp7+Unf/vByYi2tVle96MVbjXuX2BS5UELMVFIRHFjMRXAAt01p/MLgiCEFMsQE4HvE9jj81xx4IbZUinzlwF8SET7EfMSWggARDQKQI1i2QRB8BGjrqKg7biegqAZK3fsig87lDHz/yOi+Yh5Cb3L7X2bAsQ2tBcEwUhQx0sMhERM31Dpwpkq+qjXpBzeYeZFJmkb1YgjCPlBEDxFsiEMexbbzdX4ESPJepjNNLdCSTridEGZIAg5gp0OtNuokmzyBY2UC7Yc3KO6vgWbKr0N/uYXYggEwWUC3EhOIlWj2NaDKADDGap5ZEE5vvGge5swurEmw5cFZYIgCAlCpvvtJosDNaQVAvdRQRCcEiTlopiCxDqCsD60HwsJdIf6yWLvJemAGAJBcBknrbmwqE8rhRU010wzwmukvEcMgSC4RfB1IwBdGGoTi5UrQ/+pHsOXlcWK8rqBMkNARM8S0T4iWm1xnYjoESIqJ6KV+jDXghBKcrwBqp8gzhWD4RfJe0M7r0y/dyjLhOcAnGtz/TwAo7W/6wA8oVAWQfAMV7YkDIlRCbKcYRi+AoLRkVRmCJj5IwDVNlkuBPACx1gEoA8RDVQljyAoJ403OiybvlsZtTD0CGwXlHkoR6JMi8niIODnHMEgADt157u0tA4Q0XVEVEZEZVVVVZ4IJwhpE7CXOxVm4ibtQkbGa+EhlaFqC5omNiDuoyYw89PMPJGZJ5aUlPgtjiDY4sZLrLLF7YaOCcuwixX+TBZbhaFOY45AkeB+GoLdAIbozgdraYIQTlzUjYFpsCYFR7O9HDiCbKyCNrTmpyGYBeBqzXvoVAA1zLzXR3kEITuCrBUzwHaHsoApsnTxZ2OaNPJ6/GNStrkMEb0M4AwA/YloF4C7ABQDADM/CWAOgPMBlANoAHCtKlkEwUscbXqiXIrUpKsMk+YPXJZFBXbK1O85Ak7R0/IaZYaAmS9PcZ0B3KiqfEHwHBdfaL+UQxCUkjsE70HSWlAmk8WCEFJcfHmDMkeQFIbabBFUUARNk9vfWOW3CAnWVzgPdR3GBWWCkJeYeXYwM0qnz8YzC7f4IJFRGGfZUk22Br33YCf/yl3e77Qb5LUjYggEwS1sFGObpgPunbPOG1kckI1aCrgNABDsoHNubJzjJmIIBMEtbN5eY2swwI1DQRGyslgQ8gizlzzeIwjbzl5WwxmJKQIPZUmHkFWzY2SHMkEIMfFhijDppw4hJpKijwZ5uVb48Xo+QQyBIHhAkIYC4qIEefLSDcRUOUcMgSB4QFznRtsYO6sbEGltM83XGGnFoi0HPJTMOWFTqyoni+uao1iy1S64sj3G3tbmqrosJcoOMQSC4AF6pTTl/vfxh7fXm+bbUd2Ay55ehF0HG70SLQmjgkqlSoPaqVBttG55+Qt876nPcKCu2fFn7CaLp/75Q9vP9uysbO0vADEEguAJxhc/VQuwoSWqUBpnGJWp3ZxBvrF2by0AoDlq3rNzm0euOAmALCgThNBg7jUU0KazkBLzBYIZ3CcLNa7a5IohEAQPMKqAVIpE5URnOpPEYr/s6yBXOkViCATBA4zKJKWCDYCCMQ79mO9HkPuWwq0nTCfiqASdE4SQY6Yc03XV9MsOpDPuHwBbZYmb8xcq3GwzvWUu7lAmCHlDEIdYstmPIJ9wrUeQVt7k3Kon5sUQCIJC9hxqROn02XhzefIurI2RVp8kSo8A2i9T4tFd9bhluEbPmIvbZi4HADRFWrF6t/rIpbfNXKG8DD1iCATBZfQt7fUVMTfDN75INgTV9S2293C7AagfUnCq3MnwOdM5goBYCjM53Jy/iH9/M95YjQse/RgVtU1p3yPIK7nFEAiCQqKtsZe/IE3NHoRhGCJ7oxEkjxmvVOzynQdduU+Q6g4QQyAISolqYUcLC9I0BB4oCrMWs75YIkruEagXyTWCLmvQOgdiCATBZfTveDymULqGIAjEhob8lsIZfg27pNNzC/JGQGIIBEEhrfEeQdDGAhxQQJTSEATFTgRFjrAihkAQFBKUoaFMdsciMoTGMC4wC9AATBh6LkGWUQyBEDp2HGjAr15dgahFKGe/0Q9TxCeL01XsXiiNVGWsrziMd9dWqhfEBeJB4FTjd6A92aFMEDR+8e/l+FfZLizb7o4Hh0riLep0FYgXQep+P7djKGw7MYPT/u/IVc8sTjpXpa+zu20WQecUV74YAiF0BGlIwinpTma22XR2Lho/KEtp3CPIwx2Cc8QQCILLsMVxOrjdI3Djbh1apeGzx66TzqK1IBtNMQSC4AHpKoFWhVojHyKGCumh1BAQ0blEtIGIyolousn1HxBRFREt1/5+rFIeQfCcDBV6m0+62m7YLUwdAK+GD9P5et34SlUZcWUbYRJRIYDHAXwDwC4AS4loFjOvNWSdycw3qZJDELwmyVUz8T/dOYLgtNqZ2XKyOyi9C7+MlFdPr9qwqewRnAKgnJm3MHMLgFcAXKiwPEHoQF1zFB9urPKt/L01seBk6XYMVtlFuMxS+zRF2tJyvd1cVYdVu2rw+Y5DSekEYN7aysTq6XwkV3Z7U2kIBgHYqTvfpaUZuZiIVhLRq0Q0xOxGRHQdEZURUVlVlX8vtRA+fvmvFbjm2SXYWd3gS/lPfLAZgLtK4HVDJFMnGBXWUx9tcfzZsx74CN987OMO6c3RNmyuqscD721MWx4hWPg9WfwfAKXMPA7AewCeN8vEzE8z80RmnlhSUuKpgEJwcaJbN1fVAfA6/r/JDmUBGUKJs+uge4bRLyObhE9jQ1638sO4oGw3AH0Lf7CWloCZDzBzs3b6DIAJCuURBN8I2rCA1TqFEIZEMkXZgrIs7ptNYyDMC8qWAhhNRMOJqBOAywDM0mcgooG6028BWKdQHiFXCKGyCpgdcHWdQtCeTSXGSdugGfhMUeY1xMxRIroJwDsACgE8y8xriOh3AMqYeRaAm4noWwCiAKoB/ECVPILgFabKwWeFYSxe5ToFwZwgV7kyQwAAzDwHwBxD2p26498A+I1KGQQhCARtjsBVpRSsR/OUoH2vmeL3ZLEguAozI9rahtY2TvLFZ4Zn0UqjJmsA/FwW0BLt+NxB3j83TERa2fJ31dbGif0oAHeMbxgni4UA09jSimXbq/0Ww1XWV9Ti0QXlGDVjLkbePgfffeqzxLXH34+lH26KKJfjvIcXYtGWA0lpfkVK3XOoEWPumIt/l+1KSrcyTCGcfgHgn9xnPfAhRs2YiyYTr7QJ97yHr9w335VyZIcyQQm/fHUFLn7iM1TWNvktSsYYW0fnPrQwyaddr3xnrdgDADhYr94QAMAn5fs9KScVB+paAADPfrI1Kd3dyWLpXTRHOvYKDjZEUFnbnDgPcj2JIchT1mgrV+uboz5Lkj7ZtI68ehmDMvJSVBirLWPIClcNQUCe1U8o5Jo05OIL+UwmSt0rpeXFxjJOiIthlMduvwMhfdhBfQbkJ2GKGII8JR5ELMC/TUuyW9TjDUGJGRc3lkZxLA1VWCcJDHi9MM4rd1xVPVoxBHlKjrzvaaPSWyZpQ5qANP/iYhjFcdNQBeRRfaVVteUP8cpiIQTIS6yGoAwNxeUwtiSDYqhyhbDXpxgCEx6etwn/KtuZOqOB37y+Ch95HPL4759sxTMLnUeSjLS24foXl2HL/noAwA+fW+qr59DTH23GK0t2pMxXdbgZP/j7EhxqaEmkbag4jNLps/H7uc4jkzwyf1Pi+P631+P2N1bhF/9a4fqL/NeFW3HewwtdvWc6xH+/bRY9gvnr97lWllcT8HsONeKHzy1FncHB4fdz1qG2Sb3Tw51vrbYcctqqvU9m/OTFMpROn+1qoD+3EUNgwoPzNuJXr65M+3MvL9mBq59dokAia377n7W4Z7ZzRbh+72G8vaYicb6jugGPLShXIRoWbqpC6fTZKJ0+23LNwr1z1mP666tS3uuvC7fggw1VeGVpu4H+7X9iexw99aFzQ/jm8j0onT4b5fvq8JcPNuOfi3fgtc93udIzMsblX7e3NvubmtCzc+qAAPHfb6JHkMHzTRs3MHUmD/nTuxuwYP0+HHfXOxh5e3vAgnRCattRWGA//vLCZ9strxnfwTd1ocLfWVMJAKh2wXVZFpQJoWP2yr2J4wVZtkDjr6hbL4LRMLlxW6+Ggx67crzjvO1zBM5k0wdVO3vskWnJpRr9I6Qak89kR6/ORe6pw1eWduzlRrNw1QrzDmV5RdjHCFWT9Q9Z+7hbwxBGedxQ4pFWb34D3ToVOs6bze/SanvKjmVkXERaqJ6Q7eSiITDDbPVxUBBD4BJiB+zJ1p0vrrhdq2eDPEGZ3HWbxBxBBp9NMVKSwKuaU+2iWVyYWh1msy2n2erjoCCGwCUkrK892XZs3fYLL6DwxpV3qqCBdgOXiaEz1pHfqO51d3JgCMwCCpph1gNuCfDezmIIXEK5H3HYMVEq6bzY7XME7Mp4qfEOYTIE6ZhVq3UETkjH4HiB6nesuDD1A0cdDv+ZDWG6MTSkqgaU7kcQROau2osunQoxqqQHhvTt1uF6pvuvmr1oy7ZXo1/3zqiqa8aAnp1xsCGCbfvrMWpADxQVEo45qhd2H2rE9gP1+MrI/h0+v/tQI/67Yg/qm6P42dTRKC4swLLtB3FEt2KMKOmRlDfS2oa5qyvwzXEDQUTYUlWHgw0RTBh2RErZv9h5EMu2V6Ns20EM7NMVg/p0wYRhfU3z7qxuwOPvl+Pe7xyPAp2mOFDXjCc+2Izzjj8KE4b1BTPjreV7EtfjOZdsrcZRvbpgaL9uSS/2W8t3Y/zQI/DMwi349XnHAAC+8/inuOc7x+Hk0r6JAHIPz9+Eo3p3SflMcTbtqzNNbzC8lDOX7sAxA3uhuJDw/KfbcdbYI3GwvgXvrq3AzWeORqeiApw0NFaX72/Yh+MH9UZztA3z11Ui2sq4YtJQxzJli9OG+vee+gy9uhQDAPYdbk6Ru+O93ZojWLC+EicOOQJ9u3cyfI7x5vLdOO+4gfiv5lhw8fhBqKhtwsbKOuw51Iipxw7AZ5sPoKKmKeF9o//8859uS/kcTnEyR7D7UKNp+rb99bjrrdU489gj8dKi7Vi7p6PH2F8XbjX5pDNUd87yyhCs21uLn770eeJ8233TOuT52h/fz+jeZkNDFz/xmUnOdrbdNw1T//wBmiJtprKc+acP0KzFkici3PaNMbj4iU8Tn9Xz2IJyPDx/EzoVEr4yqj/O/POHpvnMWL27toOsc26egrFH9+qQd8r9sfphBv5wyTisr6jFq2W78MnmA1i3txbPfLwVf7lyPCKtbUkbxj88fxNe/2IXdlbHXqR3bj0dLy7alrh+yyvLE8eHm6LYdbARGyoP47tPfobbzhqDxVtjXj6RVk7cIxteW5YclvluzRU1TjxaKQB8Uh4LKX3DGSMx9dgBuPbvSzvcb0RJ96xlcopTnbBka3Zhxgsdap956yrxzpoKlO+rw3Wnj8Cdb63Gz84cjaP7dMXhpgh++FwZThraB2/c8FXD5/bhtpkrcNvMFYm0zkUFuHXmcket/+G/mWN5LdLahjFH9nQkf5zrvzYSP//XitQZTTjcHMXzn23H8zYuptkwekCs4XfN5FIl98+roSHjQhQzMu19ZtptbbKZQGrWbSiyt8Ze+cUXhR1siOCvLvhVX/HMItvrM7UFS1c9sxjPfLw1yWf+hpc+T4Q/1qNX4Ff9bTH+sch8Idn26gasq2i/34PzNprmy4baDPYl+MsHmy2Nu5seQ49efhIW/urrltedttTTweyWBRbaYVCfrh3SfvLiMvzxnQ1YuKkKLy/ZiTveXA2gfSjFbMGVfnFgnIMNLa4MAUVa29C/R2eMHdixMWPFReMHex6jKM7F4wd3SPu/53wpcdyvR2dsu2+asrUdeWUIVKJ6Iiudd8MNUYxhi63I9KW12y2sjVn5mL3T1q5T0q2H/73wy7bX7XzavdJV2Ric+OS0nROFyq84U8NcbGX9FOP3fExeGQKVyiXbVkwqQ+JUMQP2vvZBcZO0qy/jFn8qSLWKNF3cbgjYuTKqbLXqb23lNWT3rEY3X7vJVacTr5mQ6b19sgOm32k673y25JkhUFex2bqPplJ8brmnBsUQ2D1upJWVy1nkwEMkHdL+fmy0OQMotu0ReNN8dMNW2vndZ+OTn7JcbRVvuqt5i3yyBGbfaUQMQfjIVm+l6sq69ZtwW8Fmejc7w9ccbc35oSG70pnZ1pXRq3Fsyx6BzWeM+x/4Zgi0+bV0h4jcbiA4xayqWz3cPSivvIaq6pJd6Cprm9ASbUOX4kIUFxJqGpMnEA83RVClud0VFhCaIm0oLCAM69cNFTVN6NmlCPvrmtGzSzG2H2h3Oy3fV4eSHp1TyrOlqt21cev+evTsUoTmaCta24A+3YqT8q7ZXYMdujIqapqSXqQNlYcBANX1Ldi8r31ibn9dM6rrWxBpbUOvLsVYX3E4pVwAUNsURXV9C/bWNKKACJ2KCtC7a7JMO6sbcKjBfNK1IkVE00Ybn+rNVdaRHK1YrW296ZT9JpPZ2bDBYb06xW6s2itDYFWOnZFetSs2yb+hohYbKw9jmzZJXNMYQbnBldfMxXLdXnfqMb7wK11j43YDwSlm8zFOF6+5Qd4YgnV7a3HTP79ISpt073zbzxx/97sZlXXWAx86yhd38QSA8x+xD1m8ZX89Tte5tp76+2TZv9hxCADwx3c2JKVPvGeeI1nMGP+/79lej7uSmvG0SxEhnXLBox+nld/KHzxT/vLB5rTyDzVZw1JcSIi0Mo7u0zVpjYYRo0F2gzO/NADz1+9LGpLqWmwe0+jUEeZrTIB2D6/K2mac/eBHiXRmZ+/Fyw5CkjthQM9YQ2xo327YddD+ux47sBfWal5vp43un7T+xStGae6hp5T2xZJtMbffwSbeWarIG0OwsdLdFpsgmDFpeF9MGt4XnYsL8d7aSizfeQjTjh+I4wf3xqA+XdG1uBCjBvRAaf/ueOOGr4CI8O3HPwEArP3duVi9uyaxcO3d207HoYYI9hxqRH1LFF8Z2R/1zVEMPqLdiCz4xdcwb10l7p2zPkmO+y8eh/qWKBojrWiOtKGACH//dKtlD+5P3z0Bm/bVJRagAcAJg/vg5jNH4RFdmPL/uWAsLpkQc3V877bTsXTbQdz+hnkY8U5FBWiJtuGXZ4/BhxursHTbQdwx7VgM6NUFzJy0duSqU4di6daDiZ6tGVdOGooxR/bEXbPWoF/3Trho/CA0Rlrxz8U70MbA1ZOHobRfd5wwpE9iIeWDl56ImUt3Ym9NE0aWdMeAXl3QqZAwfugRWLb9IL58dG/06V6MyppYD/aebx+HcYP74PJThmDZ9oPYUHEYRQWUtM7k6N5dsKemvcd7+pgSy31I7r9kHGobIxg5oAfW7K7BkL7dcNyg3tiq9XpPH1OCH582HKeO6IfJI/pheP/uWLqtGhsqDuPSk4fi7C8fpXQILQ6FLWrmxIkTuaysLO3PNUdb8aU73s6ozLW/Owdj73wno88K+cXM607FpBH9EucNLVF062Tf3iqdPhuAs8V/Zp/578o9Sb3dnl2KsOruczp85vdz1lnG7k9VNjOndCeN57HK2xRpRRdDLyOuf/T542lNkTZ0TSPSqkqMz6Z/RmZGc7TN1OXXqs7mra3Ej18ow5nHDMCzPzhZqew6WZYx80Sza3nTI+hclPkPKtWLLAhxjC++F78dL7yInKwpiOexyms0AlZ542lBMQJAx2fTy01Eps8WJsRrSBBCjnHdSMBixQk2BOW7UmoIiOhcItpAROVENN3kemcimqldX0xEpSrlEYR8wGqwN1yDwIKXKDMERFQI4HEA5wEYC+ByIhpryPYjAAeZeRSABwH8QZU8gpCreLXATMhdVPYITgFQzsxbmLkFwCsALjTkuRDA89rxqwCmkoqIWoLgEV7FjNGXYwyXYbWVpZN4+4I3FGrfhertMZ2iUopBAHbqzndpaaZ5mDkKoAZAP0MeENF1RFRGRGVVVeZuWk5IFehr7MBeONoQ6/6XZ48BANw8dTRK+8Xc9o7QLfYa0b89/HDcv1pvyu6YdiyAmF/zlZOGYli/bujfozMunTgEt541Gk9eNQGXTBiMqccMwOWnDMUtU0djSN+O/sPjBvdOHHfvVNhhsU937eUfqMnfs0vyJOXxg3rjmsnD8M0TjsaNXx+Jv1w5Hp0KC9CjcxG6FBegf4/OOH1MCa6ePAw3nDESZx07AADw3LUn48henXH910bixCF9AADXTB6GqycPw8/OHIVRA3rgOyclf63D+nXDlZOG4r8/Oy1RXz/52ggAQJGmtPQ+6kP7dkvUk55+uvj1nYoKcHJp8t4K3zrhaNP6iTPj/GPxk9NHJM6NfvF6L48TBvc2jT8U9+8+5qhYSOPunQox5shY2txbpuCKSUNxwbiBmHrMAIwf2gfjh6be/8HIU9+fgGeuNnXmsGTOLVPwPxfEOtjfGHskfnrGSLx6/WT07d4Jr1w32fQzN359VIe0s44dgMeuOCltmYXsOH10CW44YyTu+fZxfosCQKH7KBFdAuBcZv6xdv59AJOY+SZdntVanl3a+WYtz36r+2bqPioIgpDP2LmPquwR7AYwRHc+WEszzUNERQB6AzigUCZBEATBgEpDsBTAaCIaTkSdAFwGYJYhzywA12jHlwBYwGFb4SYIghBylK12YeYoEd0E4B0AhQCeZeY1RPQ7AGXMPAvA3wC8SETlAKoRMxaCIAiChyhd9sjMcwDMMaTdqTtuAvBdlTIIgiAI9gTDd0kQBEHwDTEEgiAIeY4YAkEQhDxHDIEgCEKeE7r9CIioCsD2DD/eH4DlYjUfEbnSI6hyAcGVTeRKj1yUaxgzl5hdCJ0hyAYiKrNaWecnIld6BFUuILiyiVzpkW9yydCQIAhCniOGQBAEIc/JN0PwtN8CWCBypUdQ5QKCK5vIlR55JVdezREIgiAIHcm3HoEgCIJgQAyBIAhCnpM3hoCIziWiDURUTkTTPS57CBG9T0RriWgNEd2ipd9NRLuJaLn2d77uM7/RZN1AROcolG0bEa3Syi/T0voS0XtEtEn7f4SWTkT0iCbXSiIar0imL+nqZDkR1RLRrX7UFxE9S0T7tE2U4mlp1w8RXaPl30RE15iV5YJcfySi9VrZbxBRHy29lIgadfX2pO4zE7Tvv1yTPav9LC3kSvt7c/t9tZBrpk6mbUS0XEv3sr6sdIO3vzFmzvk/xMJgbwYwAkAnACsAjPWw/IEAxmvHPQFsBDAWwN0AfmmSf6wmY2cAwzXZCxXJtg1Af0Pa/QCma8fTAfxBOz4fwFwABOBUAIs9+u4qAAzzo74AnA5gPIDVmdYPgL4Atmj/j9COj1Ag19kAirTjP+jkKtXnM9xniSYrabKfp0CutL43Fe+rmVyG638GcKcP9WWlGzz9jeVLj+AUAOXMvIWZWwC8AuBCrwpn5r3M/Ll2fBjAOnTcv1nPhQBeYeZmZt4KoByxZ/CKCwE8rx0/D+DbuvQXOMYiAH2IaKBiWaYC2MzMdqvJldUXM3+E2F4ZxvLSqZ9zALzHzNXMfBDAewDOdVsuZn6XY3t/A8AixHYFtESTrRczL+KYNnlB9yyuyWWD1ffm+vtqJ5fWqv8egJft7qGovqx0g6e/sXwxBIMA7NSd74K9IlYGEZUCOAnAYi3pJq2L92y8+wdv5WUA7xLRMiK6Tks7kpn3ascVAI70Qa44lyH5BfW7voD068ePevshYi3HOMOJ6Asi+pCIpmhpgzRZvJArne/N6/qaAqCSmTfp0jyvL4Nu8PQ3li+GIBAQUQ8ArwG4lZlrATwBYCSAEwHsRax76jWnMfN4AOcBuJGITtdf1Fo+vvgYU2yL028B+LeWFIT6SsLP+rGCiGYAiAJ4SUvaC2AoM58E4OcA/klEvTwUKXDfm4HLkdzY8Ly+THRDAi9+Y/liCHYDGKI7H6yleQYRFSP2Rb/EzK8DADNXMnMrM7cB+CvahzM8k5eZd2v/9wF4Q5OhMj7ko/3f57VcGucB+JyZKzUZfa8vjXTrxzP5iOgHAC4AcKWmQKANvRzQjpchNv4+RpNBP3ykRK4Mvjcv66sIwEUAZurk9bS+zHQDPP6N5YshWApgNBEN11qZlwGY5VXh2hjk3wCsY+YHdOn68fXvAIh7NMwCcBkRdSai4QBGIzZJ5bZc3YmoZ/wYscnG1Vr5ca+DawC8pZPras1z4VQANbruqwqSWmp+15eOdOvnHQBnE9ER2rDI2VqaqxDRuQB+BeBbzNygSy8hokLteARi9bNFk62WiE7VfqNX657FTbnS/d68fF/PArCemRNDPl7Wl5VugNe/sWxmvMP0h9hs+0bErPsMj8s+DbGu3UoAy7W/8wG8CGCVlj4LwEDdZ2Zosm5Alp4JNnKNQMwjYwWANfF6AdAPwHwAmwDMA9BXSycAj2tyrQIwUWGddQdwAEBvXZrn9YWYIdoLIILYuOuPMqkfxMbsy7W/axXJVY7YOHH8N/aklvdi7ftdDuBzAN/U3WciYop5M4DHoEUbcFmutL83t99XM7m09OcAXG/I62V9WekGT39jEmJCEAQhz8mXoSFBEATBAjEEgiAIeY4YAkEQhDxHDIEgCEKeI4ZAEAQhzxFDIOQNRNRKyVFNbaNaEtH1RHS1C+VuI6L+GXzuHCL6LcUiUc5N/QlByIwivwUQBA9pZOYTnWZm5idT51LKFADva/8/9lkWIYeRHoGQ92gt9vspFmd+CRGN0tLvJqJfasc3Uyxm/EoiekVL60tEb2ppi4honJbej4jepVh8+WcQWwQUL+sqrYzlRPRUfAWrQZ5LKRYb/2YADyEWluFaIvJsNbyQX4ghEPKJroahoUt112qY+XjEVos+ZPLZ6QBOYuZxAK7X0n4L4Ast7XbEwhIDwF0APmbmLyMWv2koABDRsQAuBfBVrWfSCuBKY0HMPBOxKJSrNZlWaWV/K/NHFwRrZGhIyCfshoZe1v1/0OT6SgAvEdGbAN7U0k5DLBwBmHmB1hPohdgmKBdp6bOJ6KCWfyqACQCWxkLMoCvag4kZGYPY5iIA0J1jseoFQQliCAQhBlscx5mGmIL/JoAZRHR8BmUQgOeZ+Te2mWJbhvYHUEREawEM1IaKfsbMCzMoVxBskaEhQYhxqe7/Z/oLRFQAYAgzvw/g1wB6A+gBYCG0oR0iOgPAfo7Fkv8IwBVa+nmIbR0IxIKIXUJEA7RrfYlomFEQZp4IYDZiu1Hdj1jQtRPFCAiqkB6BkE901VrWcd5m5rgL6RFEtBJAM2Lhr/UUAvgHEfVGrFX/CDMfIqK7ATyrfa4B7WGDfwvgZSJaA+BTADsAgJnXEtEdiO0IV4BYJMwbAZhtwzkescniGwA8YHJdEFxDoo8KeQ8RbUMsnO9+v2URBD+QoSFBEIQ8R3oEgiAIeY70CARBEPIcMQSCIAh5jhgCQRCEPEcMgSAIQp4jhkAQBCHP+f8l4hKrLl2+QgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Future ideas\n",
    "\n",
    "During the training it is found that the replay buffer size is important to the stabilize the learning. When the buffer size is set to a small value, the agent's single successful episode could fill up the buffer, and force the agent to learn from only that episode's data which led to unstatble scores. Thus what the agent learns from is criticle for the stability of the training. So to further improve the scores, it is believed that the prioritization of the replay buffer experiences would do the help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 2.7000000402331352\n",
      "Score (max over agents) from episode 2: 2.600000038743019\n",
      "Score (max over agents) from episode 3: 2.7000000402331352\n",
      "Score (max over agents) from episode 4: 2.7000000402331352\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TennisBrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ea2edd176d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# all actions between -1 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m# send all actions to tne environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m         \u001b[0;31m# get next state (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m                         \u001b[0;31m# get reward (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_external_brain_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_agents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TennisBrain'"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = agent.act(states, noise_level=0)              # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: Ran out of input\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 26, in Exchange\n",
      "    return self.child_conn.recv()\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "EOFError: Ran out of input\n",
      "ERROR:root:Exception calling application: [Errno 104] Connection reset by peer\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 26, in Exchange\n",
      "    return self.child_conn.recv()\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 411, in _recv_bytes\n",
      "    return self._recv(size)\n",
      "  File \"/home/labassistant/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
